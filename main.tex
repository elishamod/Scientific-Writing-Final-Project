%% AASTeX v7+ calls the following external packages:
%% times, hyperref, ifthen, hyphens, longtable, xcolor, 
%% bookmarks, array, rotating, ulem, and lineno 
\documentclass[twocolumn]{aastex701}

\usepackage{booktabs}
\usepackage[table]{xcolor}
\usepackage{colortbl}
\usepackage{natbib}
\usepackage{float}

\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}

\begin{document}

\title{A Robust, Novel, and Comprehensive Insight: Leveraging a Framework to Utilize Buzzwords in Scientific Abstracts}

\author[orcid=0000-0003-4105-3443]{Elisha Modelevsky}
\affiliation{Racah Institute of Physics, Hebrew University of Jerusalem}
\email[show]{elisha.modelevsky@mail.huji.ac.il}  

%% Mark off the abstract in the ``abstract'' environment. 
\begin{abstract}

Large language models (LLMs) have been rapidly adopted across scientific workflows, and their influence on scientific work has been observed in many studies.
We quantify changes in vocabulary usage in arXiv abstracts by analyzing astrophysics subcategories (astro-ph.CO/EP/GA/HE/IM/SR) alongside other physics areas (cond-mat, hep, nucl) and computer science (cs).
Using the arXiv API, we collect up to 250 abstracts per month per category from January 2019 through June 2025, and measure frequencies for a curated list of terms that are commonly associated with LLM-generated text, along with some comparison terms.
We calculate the post-ChatGPT factor increase relative to a pre-ChatGPT baseline (threshold December 2022) for each category, and assess significance with z-tests.
We find statistically significant increases in LLM-favored vocabulary across all domains after the introduction of ChatGPT, with the greatest change in computer science.
Physics categories exhibit more modest increases, without major differences between them, except for a lower baseline in High Energy and Nuclear Physics.
Differences among astrophysics subfields are even less significant.


\end{abstract}

% \keywords{\uat{Galaxies}{573}}
%% You can use the \uat command to link your UAT concepts back its source.
% \keywords{\uat{Galaxies}{573} --- \uat{Cosmology}{343} --- \uat{High Energy astrophysics}{739} --- \uat{Interstellar medium}{847} --- \uat{Stellar astronomy}{1583} --- \uat{Solar physics}{1476}}

\section{Introduction} 

ChatGPT was introduced on 30 November 2022 by OpenAI as a revolutionary large language model (LLM), capable of understanding and generating human-like text \citep{Roumeliotis2023}.
Since its release, many other LLMs with similar capabilities have emerged, and these models are now widely used for various tasks, including writing and coding \citep{Minaee2024}.
The influence of LLMs on science is an ongoing discussion -- while they can be very useful and efficient for many stages in the scientific process, some researchers express concerns about the potential for misuse and the impact on scientific integrity \citep{Zhang2025}.

Another aspect of science where the footprint of LLMs is very apparent is scientific writing.
Previous studies have demonstrated linguistic shifts in scientific language;
notably, some studies have found a significant increase in the use of certain words and phrases since the introduction of ChatGPT \citep{Kobak2025,Bao2025,Juzek2024}.
An interesting phenomenon highlighted by \citet{Lin2025} is the ``equalization'' of scientific language across countries of origin, characterized by a reduction in linguistic differences between native and non-native English-speaking authors.

Prior studies have investigated linguistic shifts in general scientific writing and in select disciplines \citep{Xu2024,Kobak2025,Bao2025}, but to our knowledge, a systematic analysis focusing specifically on astrophysics has not yet been conducted.
This work aims to fill this gap by examining the change in vocubalary in astrophysics abstracts since the introduction of ChatGPT, and comparing it to other branches of physics.
We also investigate whether different subfields within astrophysics have been affected differently.


\section{Methods}

To gather the data, we use the arXiv API to collect abstracts from papers in each of the astrophysics subcategories (astro-ph.CO/EP/GA/HE/IM/SR) and several other physics categories (cond-mat, hep, nucl) as well as Computer Science (cs).
Due to API limitations, we collect a maximum of 250 abstracts per month from each category, spanning from January 2019 to June 2025.

In each abstract, we count the occurrences of each word in a predefined list of words (see Table~\ref{tab:factor_increase} for the word list).
The words in this list are those that have been commonly cited as overused by LLMs \citep{Bao2025,Kobak2025}, as well as some words that are not expected to be overused.
The usage statistics are aggregated by yearly quarters and arXiv category.
Figure~\ref{fig:word_usage_trends_example} shows an example of the usage trends of several words in the astro-ph category.

To determine the factor increase in word usage, we calculate the ratio of the frequency of each word in abstracts after the introduction of ChatGPT to its frequency before.
We then perform a z-test to assess the statistical significance of the change in frequency for each word.


\section{Results}

Table~\ref{tab:factor_increase} shows statistically significant factor increases in word usage after the introduction of ChatGPT, broken down by arXiv category.
Similarly to previous findings \citep{Juzek2024,Bao2025,Kobak2025}, words such as ``delve'', ``leverage'', ``intricate'', ``valuable'' and ``pivotal'' have seen a significant increase in usage across all categories.
However, some words that were reported as overused, such as ``foster'', ``boast'', ``remarkable'', ``thereby'' and ``innovative'' have seen a significant increase in only some of the categories.
In particular, all of these words' usage has increased significantly in the Computer Science category, but not in all of the physics categories.

Regarding the different astrophysics subcategories, no particular trend was observed to distinguish between them.

We identify words that are strong suspects of being overused due to LLMs by looking for words that have seen a significant increase in usage of at least 50\% in at least 3 of the major categories (astro-ph, cond-mat, hep, nucl, cs).
These words appear in Table~\ref{tab:factor_increase} in boldface.
To quantify the overall influence of LLMs on scientific writing in each category, we define an \emph{``LLM influence score''} as number of appearances of these strong suspect words per abstract.

Figures~\ref{fig:category_comparison} and \ref{fig:astro_subcat_comparison} show the LLM influence score over time in different arXiv categories and astro-ph subcategories, respectively.
While there is no clear difference between the astrophysics subcategories, it seems that LLM-favored words were always more prevalent in astro-ph.IM (Instrumentation and Methods for Astrophysics) and in astro-ph.EP (Earth and Planetary Astrophysics).

The category comparison in Figure~\ref{fig:category_comparison} reveals that the Computer Science category has been the most affected by LLMs, with a significant increase in the LLM influence score after the introduction of ChatGPT.
That remains true even after subtracting the baseline of LLM-favored words usage, which was higher in Computer Science abstracts than in physics even before the introduction of ChatGPT.

Table~\ref{tab:expected_words_per_abstract_before_after} shows the expected number of LLM-favored words per abstract in each category, before and after the introduction of ChatGPT.
Besides the clear strong influence on Computer Science, it can be seen that the in the changes in physics categories are more modest, and are similar to one another.
Interestingly, High Energy Physics (hep) and Nuclear Physics (nucl) have had a lower baseline (LLM-favored word usage prior to ChatGPT) than Condensed Matter Physics (cond-mat) and Astrophysics (astro-ph).


\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{scripts/figs/major_cats_score_vs_time.pdf}
\caption{
LLM influence score over time in different arXiv categories.
The bottom panel shows the baselined score (the score minus the average score before ChatGPT).
The red vertical line indicates the introduction of ChatGPT (2022-Q4).
}
\label{fig:category_comparison}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{scripts/figs/astro_subcats_score_vs_time.pdf}
\caption{
LLM influence score over time in different astro-ph subcategories.
The bottom panel shows the baselined score (the score minus the average score before ChatGPT).
The red vertical line indicates the introduction of ChatGPT (2022-Q4).
}
\label{fig:astro_subcat_comparison}
\end{figure}

\begin{table}
\centering
\begin{tabular}{lccc}
\toprule
Category & Before & After & Difference \\
\midrule
astro-ph & 0.294 & 0.509 & 0.215 \\
cond-mat & 0.267 & 0.490 & 0.223 \\
hep & 0.160 & 0.346 & 0.186 \\
nucl & 0.177 & 0.398 & 0.221 \\
cs & 0.462 & 1.053 & 0.591 \\
\bottomrule
\end{tabular}
\caption{Expected number of LLM-favored words per abstract in each category, before and after the introduction of ChatGPT.}
\label{tab:expected_words_per_abstract_before_after}
\end{table}


\section{Summary \& Discussion}

We analyzed vocabulary shifts in arXiv abstracts (from January 2019 to June 2025) across astrophysics subcategories, other physics (cond-mat, hep, nucl), and computer science.
In this study, we investigated the impact of large language models (LLMs) on the vocabulary used in arXiv abstracts across astrophysics subcategories, several physics categories, and computer science.
Our analysis revealed a significant increase in the usage of LLM-favored words in all categories following the introduction of ChatGPT.
Computer science is the most strongly affected, whereas the physics categories show more modest increases that are similar to one another -- though High Energy Physics and Nuclear Physics have a lower baseline than Astrophysics and Condensed Matter Physics.
No significant differences were observed between the astrophysics subcategories.

Future investigations could expand the vocabulary list to include more words and phrases associated with LLM-generated text, and could also analyze the full text of papers rather than just abstracts.
In particular, a known effect of LLMs is the increased usage of em-dashes, which was not included in this study after it was found that abstracts rarely include em-dashes.
A more thorough analysis should be able to estimate more confidently the percentage of papers that were written with the help of LLMs, and how that percentage varies across disciplines -- potentially revealing more pronounced effects than what we have been able to observe.


\section*{Acknowledgments}
The author thanks his colleague Nadav Shoval for helpful discussions and comments.

\bibliography{references}{}
\bibliographystyle{aasjournalv7}

\appendix 
\renewcommand{\thesection}{\Alph{section}}
\renewcommand{\thefigure}{\Alph{section}\arabic{figure}}
\renewcommand{\thetable}{\Alph{section}\arabic{table}}

\section{Example word usage trends}
\setcounter{figure}{0}
\setcounter{table}{0}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{scripts/figs/example_usage_vs_time_astro-ph.pdf}
\caption{
Example of word usage trends over time in the astro-ph category -- the fraction of abstracts containing each word is plotted over time (in quarters).
The red vertical line indicates the introduction of ChatGPT (2022-Q4).
The gray shaded area reprensents the mean fraction before and after the introduction of ChatGPT.
}
\label{fig:word_usage_trends_example}
\end{figure*}

\section{Factor increase table for all words and categories}
\setcounter{figure}{0}
\setcounter{table}{0}

\begin{table*}[ht]
\centering
\scriptsize
\setlength{\tabcolsep}{3pt}
\input{scripts/ztest/colored_factor_increase_table.tex}
\caption{
Factor increase in word usage since the introduction of ChatGPT (threshold December 2022), by arXiv category.
Blank cells indicate non-significant changes ($p \geq 0.05$).
The color scale indicates the magnitude of the factor increase, with darker green representing larger increases, and darker red representing larger decreases.
The words in boldface are those that have seen a significant increase of at least 50\% in at least 3 of the 5 major categories.
Note that the words ``delv'', ``leverag'', and ``utiliz'' are stemmed to include all their morphological variants (e.g., ``delve'' and ``delving'').
}
\label{tab:factor_increase}
\end{table*}

\end{document}
